from openai import OpenAI
import os
import json
from dotenv import load_dotenv
from weather_func import get_weather


load_dotenv()  # è½½å…¥ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
'''deepseek'''
# API_KEY = os.getenv("DEEPSEEK_API_KEY")
# BASE_URL = os.getenv("DEEPSEEK_BASE_URL")
# MODEL = os.getenv("DEEPSEEK_MODEL_CHAT")
'''é˜¿é‡Œå¤§æ¨¡å‹'''
API_KEY = os.getenv("ALI_API_KEY")
BASE_URL = os.getenv("ALI_BASE_URL")
MODEL = os.getenv("ALI_MODEL_QWEN")

# åˆå§‹åŒ–å¯¹è¯ä¸Šä¸‹æ–‡
conversation_history = []  # å­˜å‚¨æ‰€æœ‰ç”¨æˆ·å’Œ AI çš„å¯¹è¯å†…å®¹
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–ä¸€ä¸ªåœ°ç‚¹çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "ä½ç½®åœ°ç‚¹",
                    }
                },
                "required": ["location"]
            },
        }
    },
]


def llm_call(**kwargs):
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    response = client.chat.completions.create(
        model=MODEL,
        messages=kwargs.get("messages"),
        stream=kwargs.get("stream"),
        tools=kwargs.get("tools")
    )

    return response


def chat_loop():
    """è¿è¡Œäº¤äº’å¼å¯¹è¯å¾ªç¯ï¼Œç»´æŠ¤ä¸Šä¸‹æ–‡"""
    print("\nğŸš€ å¯¹è¯åŠ©æ‰‹å¯åŠ¨æˆåŠŸï¼")
    print("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼Œè¾“å…¥ 'q' å¯ç»“æŸå¯¹è¯ã€‚\n")

    while True:
        user_input = input("ğŸ‘¤ ä½ : ").strip()

        if user_input.lower() == "q":
            print("ğŸ›‘ ç»“æŸå¯¹è¯ï¼Œå†è§ï¼")
            break

        # è®°å½•ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯å†å²
        conversation_history.append({"role": "user", "content": user_input})
        # å‘é€è¯·æ±‚
        response = llm_call(messages=conversation_history, tools=tools)

        if response:
            message = response.choices[0].message
            # print(message)
            # å·¥å…·å­—æ®µ
            tool = message.tool_calls
            if tool is not None:
                conversation_history.append({
                    "role": "assistant",
                    "tool_calls": [
                        {
                            "id": tool[0].id,
                            "type": "function",
                            "function": {
                                "name": tool[0].function.name,
                                "arguments": tool[0].function.arguments,
                            }
                        }
                    ]
                })
                print("-"*50)
                print("å·¥å…·è°ƒç”¨ï¼š", tool)
                print("-"*50)
                weather_content = ""
                location = json.loads(tool[0].function.arguments)["location"]
                if tool[0].function.name == "get_weather":
                    weather_content = get_weather(location)                   # è°ƒç”¨å‡½æ•° get_weather !
                conversation_history.append({"role": "tool", "tool_call_id": tool[0].id, "content": weather_content})
                # print(conversation_history)
                print("*"*50)
                for c in conversation_history:
                    print(c)
                print("*"*50)
                response_agin = llm_call(messages=conversation_history, tools=tools)
                print("ğŸ¤– AI:", response_agin.choices[0].message.content)
            else:
                print("*" * 50)
                for c in conversation_history:
                    print(c)
                print("*" * 50)
                print("ğŸ¤– AI:", message.content)
                conversation_history.append({"role": "assistant", "content": message.content})

            # print(ai_response)

            # è®°å½• AI å›å¤åˆ°å¯¹è¯å†å²
            print("\n")  # æ¢è¡Œ
        else:
            print("âš ï¸ AI å“åº”å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚")


# å¯åŠ¨èŠå¤©
if __name__ == "__main__":

    chat_loop()
